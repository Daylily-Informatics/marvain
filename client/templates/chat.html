<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Chat — marvain</title>
  <link rel="stylesheet" href="/static/css/panels.css" />
  <style>
    body { font-family: system-ui, -apple-system, Arial, sans-serif; margin: 24px; line-height: 1.35; }
    #conversation { border: 1px solid #ddd; border-radius: 10px; padding: 12px; height: 45vh; overflow-y: auto; background: #fff; }
    .msg { margin: 8px 0; padding: 8px 10px; border-radius: 10px; max-width: 72ch; }
    .user { border: 1px solid #cfd; background: #f0fff0; }
    .agent { border: 1px solid #ddf; background: #f0f0ff; }
    .meta { color: #666; font-size: 0.92em; }
    #input-area { display:flex; gap: 8px; margin-top: 10px; align-items: center; flex-wrap: wrap; }
    input[type="text"] { padding: 9px; border-radius: 10px; border: 1px solid #bbb; min-width: 320px; flex: 1; }
    button { padding: 9px 10px; border-radius: 10px; border: 1px solid #bbb; background: #fff; cursor:pointer; }
    button:hover { border-color: #888; }
    .row { display:flex; gap: 10px; flex-wrap: wrap; align-items: center; }
    select { padding: 6px; border-radius: 8px; border: 1px solid #bbb; max-width: 360px; }
    .pill { border: 1px solid #ddd; border-radius: 999px; padding: 4px 9px; font-size: 0.85em; }
    .card { border: 1px solid #ddd; border-radius: 10px; padding: 12px; margin-top: 14px; }
    #statusPanel { background: #f8f9fa; }
    #statusPanel strong { color: #495057; }
    #memoryPanel { background: #fefefe; max-height: 250px; overflow-y: auto; }
    #toolDetails { background: #f1f3f4; padding: 6px 10px; border-radius: 6px; font-family: monospace; font-size: 0.85em; }
    .debug-log { max-height: 180px; overflow-y: auto; background: #f7f7f7; border: 1px solid #eee; padding: 8px; border-radius: 8px; }
    .debug-tools { display: grid; gap: 10px; margin-top: 10px; }
    .debug-tool { border: 1px dashed #ccc; padding: 8px; border-radius: 8px; }
    .debug-tool-title { font-weight: 600; }
    .debug-output { background: #0b1021; color: #e3e3e3; padding: 10px; border-radius: 8px; white-space: pre-wrap; max-height: 260px; overflow-y: auto; }
    .nav { display: flex; gap: 12px; margin-bottom: 12px; }
    .nav a { padding: 6px 12px; border: 1px solid #ddd; border-radius: 8px; text-decoration: none; color: inherit; }
    .nav a:hover { background: #f5f5f5; }
    .side-panels { display: grid; grid-template-columns: 1fr 1fr; gap: 14px; margin-top: 14px; }
    @media (max-width: 900px) { .side-panels { grid-template-columns: 1fr; } }
  </style>
</head>
<body>
  <h1>Chat</h1>
  <div class="nav">
    <a href="/">← Home</a>
    <a href="/speakers">Speakers</a>
    <a href="/memories">Memories</a>
  </div>
  <div class="meta">
    Connected to: <strong>{{ stack_name }}</strong>
    (<code>{{ state.selected_endpoint }}</code>)
    <div>Session: <strong>{{ state.selected_session or "Auto-generated" }}</strong>{% if not state.selected_session %} (new ID will be generated as you chat){% endif %}</div>
  </div>

  <div class="row" style="margin-top: 10px;">
    <label class="pill">
      ASR mode:
      <select id="asrMode">
        <option value="server" selected>Server (AWS Transcribe)</option>
        <option value="browser">Browser (Web Speech API fallback)</option>
      </select>
    </label>
    <label class="pill">
      Language:
      <select id="languageCode">
        <option value="en-US" selected>en-US</option>
        <option value="en-GB">en-GB</option>
        <option value="es-US">es-US</option>
        <option value="fr-FR">fr-FR</option>
      </select>
    </label>
    <button id="enableAudioBtn">Enable audio</button>
    <span class="pill" id="asrStatus">ASR: idle</span>
    <span class="pill" id="partialPill" style="display:none;"></span>
  </div>

  <div class="row" style="margin-top: 10px;">
    <span class="pill">Push-to-talk: <button id="pttBtn">Hold to talk</button></span>
    <label class="pill">
      <input type="checkbox" id="ambientToggle" /> Ambient listening
    </label>
    <span class="pill meta">Output device selection needs Chrome/Edge + HTTPS/localhost.</span>
  </div>

  <div class="row" style="margin-top: 10px;">
    <div>
      <div class="meta">Audio input device</div>
      <select id="audioIn"></select>
    </div>
    <div>
      <div class="meta">Audio output device</div>
      <select id="audioOut"></select>
    </div>
    <div>
      <div class="meta">Video input device (display only)</div>
      <select id="videoIn"></select>
    </div>
  </div>

  <div id="conversation" style="margin-top: 12px;"></div>

  <div id="input-area">
    <input type="text" id="user_input" placeholder="Type your message"
           onkeydown="if(event.key==='Enter'){ sendMessage(); }" />
    <button onclick="sendMessage()">Send</button>
  </div>

  <div class="row" style="margin-top: 10px;">
    <div class="meta">Optional extra personality prompt (sent with each message)</div>
    <input type="text" id="persona_input" placeholder="e.g. be terse, ask clarifying questions, etc." style="min-width: 520px;" />
  </div>

  <div class="row" style="margin-top: 10px;">
    <div class="meta">Optional speaker name (helps voice registry)</div>
    <input type="text" id="speaker_name_input" placeholder="e.g. Major" style="min-width: 260px;" />
  </div>

  <!-- Speaker & Tool Status Panel -->
  <div class="card" id="statusPanel" style="display: none;">
    <div class="row" style="gap: 20px;">
      <div id="speakerStatus">
        <strong>Speaker:</strong> <span id="currentSpeaker">Unknown</span>
        <span id="speakerBadge" class="pill" style="display: none;"></span>
      </div>
      <div id="toolStatus" style="display: none;">
        <strong>Tools:</strong> <span id="toolIterations">-</span>
        <span id="toolProgress" class="pill"></span>
      </div>
    </div>
    <div id="toolDetails" class="meta" style="margin-top: 8px; display: none;"></div>
  </div>

  <!-- Memory Context Panel -->
  <div class="card" id="memoryPanel" style="display: none;">
    <h3 style="margin-top: 0;">Recent Context</h3>
    <div id="memoryList" style="max-height: 150px; overflow-y: auto;"></div>
    <button onclick="loadMemories()" class="btn" style="margin-top: 8px;">Refresh Memories</button>
  </div>

  <div class="card" id="debugCard">
    <h2 style="margin-top:0">Debug</h2>
    <div class="meta">Verbose logging is {{ 'enabled' if state.verbose else 'disabled' }} (toggle in <a href="/settings">Settings</a>).</div>
    <div class="meta">Use the tools below to run debug helpers and view their output directly in the GUI.</div>
    <div id="verboseLogs" class="debug-log"></div>
    <div class="debug-tools" id="debugTools"></div>
    <pre id="debugOutput" class="debug-output"></pre>
  </div>

  <p style="margin-top: 12px;"><a href="/">← Back</a></p>

<script>
  const verboseEnabled = {{ 'true' if state.verbose else 'false' }};
  const convo = document.getElementById('conversation');

  const asrModeSel = document.getElementById('asrMode');
  const languageSel = document.getElementById('languageCode');
  const enableAudioBtn = document.getElementById('enableAudioBtn');
  const pttBtn = document.getElementById('pttBtn');
  const ambientToggle = document.getElementById('ambientToggle');
  const asrStatus = document.getElementById('asrStatus');
  const partialPill = document.getElementById('partialPill');

  const audioInSel = document.getElementById('audioIn');
  const audioOutSel = document.getElementById('audioOut');
  const videoInSel = document.getElementById('videoIn');
  const debugLogBox = document.getElementById('verboseLogs');
  const debugOutput = document.getElementById('debugOutput');
  const debugToolsContainer = document.getElementById('debugTools');

  let selectedOutputDeviceId = null;
  let selectedMicDeviceId = null;

  function appendMsg(role, text) {
    const div = document.createElement('div');
    div.className = 'msg ' + role;
    div.textContent = text;
    convo.appendChild(div);
    convo.scrollTop = convo.scrollHeight;
  }

  function appendMeta(text) {
    const div = document.createElement('div');
    div.className = 'meta';
    div.textContent = text;
    convo.appendChild(div);
    convo.scrollTop = convo.scrollHeight;
  }

  function appendDebugLog(text) {
    if (!debugLogBox) return;
    const div = document.createElement('div');
    div.textContent = text;
    debugLogBox.appendChild(div);
    debugLogBox.scrollTop = debugLogBox.scrollHeight;
  }

  function setDebugOutput(text) {
    if (!debugOutput) return;
    debugOutput.textContent = text || '';
  }

  // Speaker and tool status management
  const statusPanel = document.getElementById('statusPanel');
  const currentSpeakerEl = document.getElementById('currentSpeaker');
  const speakerBadgeEl = document.getElementById('speakerBadge');
  const toolStatusEl = document.getElementById('toolStatus');
  const toolIterationsEl = document.getElementById('toolIterations');
  const toolProgressEl = document.getElementById('toolProgress');
  const toolDetailsEl = document.getElementById('toolDetails');
  const memoryPanel = document.getElementById('memoryPanel');
  const memoryListEl = document.getElementById('memoryList');

  function updateSpeakerStatus(speakerInfo) {
    if (!speakerInfo) return;
    statusPanel.style.display = 'block';

    const name = speakerInfo.speaker_name || speakerInfo.current_speaker_name || 'Unknown';
    const voiceId = speakerInfo.voice_id || speakerInfo.current_speaker_voice_id || '';
    const isNew = speakerInfo.is_new_speaker || speakerInfo.is_new_voice || false;

    currentSpeakerEl.textContent = name;

    if (isNew) {
      speakerBadgeEl.textContent = 'New Speaker';
      speakerBadgeEl.style.background = '#ffe066';
      speakerBadgeEl.style.display = 'inline-block';
    } else if (voiceId) {
      speakerBadgeEl.textContent = 'Recognized';
      speakerBadgeEl.style.background = '#90EE90';
      speakerBadgeEl.style.display = 'inline-block';
    } else {
      speakerBadgeEl.style.display = 'none';
    }
  }

  function updateToolStatus(toolInfo) {
    if (!toolInfo || !toolInfo.tool_calls || toolInfo.tool_calls.length === 0) {
      toolStatusEl.style.display = 'none';
      toolDetailsEl.style.display = 'none';
      return;
    }

    statusPanel.style.display = 'block';
    toolStatusEl.style.display = 'block';

    const iterations = toolInfo.iterations || 1;
    const calls = toolInfo.tool_calls || [];

    toolIterationsEl.textContent = `${iterations} iteration(s)`;
    toolProgressEl.textContent = `${calls.length} tool(s) executed`;

    // Show tool details
    if (calls.length > 0) {
      toolDetailsEl.style.display = 'block';
      toolDetailsEl.innerHTML = calls.map(c =>
        `<div>• ${c.name}: ${JSON.stringify(c.input).substring(0, 50)}...</div>`
      ).join('');
    }
  }

  function displayMemoryItem(memory) {
    const div = document.createElement('div');
    div.className = 'msg';
    div.style.fontSize = '0.9em';
    div.style.padding = '4px 8px';

    const kind = memory.kind || 'UNKNOWN';
    const text = memory.text || '';
    const speaker = memory.speaker_id || memory.meta?.speaker_id || '';

    // Color by kind
    const kindColors = {
      'FACT': '#e3f2fd',
      'PREFERENCE': '#fff3e0',
      'AI_INSIGHT': '#f3e5f5',
      'RELATIONSHIP': '#e8f5e9',
      'ACTION': '#fce4ec',
      'META': '#f5f5f5'
    };
    div.style.background = kindColors[kind] || '#fff';

    let html = `<strong>[${kind}]</strong> ${text}`;
    if (speaker) html += ` <em>(${speaker})</em>`;
    div.innerHTML = html;

    return div;
  }

  async function loadMemories() {
    try {
      const resp = await fetch('/api/memories?limit=20');
      if (!resp.ok) throw new Error('Failed to load memories');
      const data = await resp.json();

      memoryPanel.style.display = 'block';
      memoryListEl.innerHTML = '';

      (data.memories || []).forEach(m => {
        memoryListEl.appendChild(displayMemoryItem(m));
      });

      if (!data.memories || data.memories.length === 0) {
        memoryListEl.innerHTML = '<div class="meta">No memories found</div>';
      }
    } catch (e) {
      appendMeta('Failed to load memories: ' + e);
    }
  }

  function setAsrStatus(t) {
    asrStatus.textContent = 'ASR: ' + t;
  }

  function setPartial(text) {
    if (!text) {
      partialPill.style.display = 'none';
      partialPill.textContent = '';
      return;
    }
    partialPill.style.display = 'inline-block';
    partialPill.textContent = 'partial: ' + text;
  }

  // Downsample Float32 audio buffer to 16kHz for AWS Transcribe.
  // Uses a simple averaging approach (good enough for speech).
  function downsampleBuffer(buffer, inputSampleRate, outputSampleRate) {
    if (outputSampleRate === inputSampleRate) {
      return buffer;
    }
    const sampleRateRatio = inputSampleRate / outputSampleRate;
    const newLength = Math.round(buffer.length / sampleRateRatio);
    const result = new Float32Array(newLength);
    let offsetResult = 0;
    let offsetBuffer = 0;
    while (offsetResult < result.length) {
      const nextOffsetBuffer = Math.round((offsetResult + 1) * sampleRateRatio);
      // average the samples in the old buffer between these two points
      let accum = 0;
      let count = 0;
      for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++) {
        accum += buffer[i];
        count++;
      }
      result[offsetResult] = count > 0 ? (accum / count) : 0;
      offsetResult++;
      offsetBuffer = nextOffsetBuffer;
    }
    return result;
  }

  async function playAgentAudio(audioObj) {
    try {
      const audio = new Audio();
      if (audioObj.url) audio.src = audioObj.url;
      else if (audioObj.data && audioObj.content_type) audio.src = 'data:' + audioObj.content_type + ';base64,' + audioObj.data;
      else return;

      // Route playback to selected output device when supported.
      if (selectedOutputDeviceId && typeof audio.setSinkId === 'function') {
        try { await audio.setSinkId(selectedOutputDeviceId); } catch(e) { /* ignore */ }
      }
      await audio.play();
    } catch (e) {
      appendMeta('audio playback failed: ' + e);
    }
  }

  async function sendToAgent(messageText) {
    const persona = (document.getElementById('persona_input').value || '').trim();
    try {
      const response = await fetch('/api/send_message', {
        method: 'POST',
        headers: {'Content-Type': 'application/json'},
        body: JSON.stringify({ text: messageText, personality_prompt: persona })
      });
      const data = await response.json();
      if (!response.ok || data.error) {
        appendMsg('agent', '[Error] ' + (data.error || ('HTTP ' + response.status)));
        return;
      }
      if (data.reply_text) appendMsg('agent', data.reply_text);
      if (data.actions && data.actions.length) appendMeta('actions: ' + JSON.stringify(data.actions));
      if (data.verbose_logs) data.verbose_logs.forEach((log) => { appendDebugLog(log); if (verboseEnabled) appendMeta('[verbose] ' + log); });
      if (data.audio) await playAgentAudio(data.audio);
    } catch (e) {
      appendMsg('agent', '[Error] Agent not reachable');
    }
  }

  async function sendMessage() {
    const input = document.getElementById('user_input');
    const text = (input.value || '').trim();
    if (!text) return;
    appendMsg('user', text);
    input.value = '';
    await sendToAgent(text);
  }

  // --- Device enumeration + selection ---
  function addOpt(sel, label, value) {
    const o = document.createElement('option');
    o.value = value;
    o.textContent = label;
    sel.appendChild(o);
  }

  async function refreshDevices() {
    const devices = await navigator.mediaDevices.enumerateDevices();

    const prevMic = audioInSel.value;
    const prevOut = audioOutSel.value;
    const prevVid = videoInSel.value;

    audioInSel.innerHTML = '';
    audioOutSel.innerHTML = '';
    videoInSel.innerHTML = '';

    const mics = devices.filter(d => d.kind === 'audioinput');
    const outs = devices.filter(d => d.kind === 'audiooutput');
    const cams = devices.filter(d => d.kind === 'videoinput');

    mics.forEach((d, i) => addOpt(audioInSel, d.label || ('mic ' + (i+1)), d.deviceId));
    outs.forEach((d, i) => addOpt(audioOutSel, d.label || ('speaker ' + (i+1)), d.deviceId));
    cams.forEach((d, i) => addOpt(videoInSel, d.label || ('camera ' + (i+1)), d.deviceId));

    if (prevMic) audioInSel.value = prevMic;
    if (prevOut) audioOutSel.value = prevOut;
    if (prevVid) videoInSel.value = prevVid;

    selectedMicDeviceId = audioInSel.value || null;
    selectedOutputDeviceId = audioOutSel.value || null;
  }

  enableAudioBtn.addEventListener('click', async () => {
    try {
      // Request permissions so device labels are available.
      const constraints = { audio: true, video: false };
      const s = await navigator.mediaDevices.getUserMedia(constraints);
      s.getTracks().forEach(t => t.stop());
      await refreshDevices();
      appendMeta('audio permissions granted');
    } catch (e) {
      appendMeta('audio permission failed: ' + e);
    }
  });

  audioInSel.addEventListener('change', () => {
    selectedMicDeviceId = audioInSel.value || null;
    // Restart capture with new device if running.
    if (serverAsr.captureActive) {
      serverAsr.stopCapture();
      // If ambient is enabled, restart capture.
      if (ambientToggle.checked && asrModeSel.value === 'server') {
        serverAsr.startCapture().catch(e => appendMeta('capture restart failed: ' + e));
      }
    }
  });

  audioOutSel.addEventListener('change', () => {
    selectedOutputDeviceId = audioOutSel.value || null;
  });

  // --- Server-side ASR (AWS Transcribe streaming via FastAPI websocket) ---
  const serverAsr = {
    ws: null,
    wsCanSend: false,
    sessionActive: false,
    captureActive: false,
    audioCtx: null,
    processor: null,
    source: null,
    stream: null,
    gain: null,
    preRoll: [],
    preRollMax: 6,
    lastVoiceMs: 0,
    vadThreshold: 0.020,
    silenceMs: 900,

    async startCapture() {
      if (this.captureActive) return;
      const deviceId = selectedMicDeviceId;
      const constraints = {
        audio: {
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          ...(deviceId ? { deviceId: { exact: deviceId } } : {})
        },
        video: false
      };

      this.stream = await navigator.mediaDevices.getUserMedia(constraints);
      const AC = window.AudioContext || window.webkitAudioContext;
      // Ask for 16k; browser will resample if needed.
      this.audioCtx = new AC({ sampleRate: 16000 });
      this.source = this.audioCtx.createMediaStreamSource(this.stream);

      // ScriptProcessor is widely supported; buffer size 2048 keeps latency reasonable.
      this.processor = this.audioCtx.createScriptProcessor(2048, 1, 1);
      this.gain = this.audioCtx.createGain();
      this.gain.gain.value = 0; // prevent audible loopback

      this.source.connect(this.processor);
      this.processor.connect(this.gain);
      this.gain.connect(this.audioCtx.destination);

      this.processor.onaudioprocess = (e) => {
        const input = e.inputBuffer.getChannelData(0);
        if (!input) return;

        // Ensure we feed AWS Transcribe 16kHz PCM.
        const inRate = (this.audioCtx && this.audioCtx.sampleRate) ? this.audioCtx.sampleRate : 16000;
        const buf = (inRate === 16000) ? input : downsampleBuffer(input, inRate, 16000);

        // Compute RMS for simple VAD.
        let sum = 0;
        for (let i = 0; i < buf.length; i++) sum += buf[i] * buf[i];
        const rms = Math.sqrt(sum / buf.length);
        const now = performance.now();

        // Convert Float32 [-1,1] to Int16 PCM LE.
        const ab = new ArrayBuffer(buf.length * 2);
        const dv = new DataView(ab);
        for (let i = 0; i < buf.length; i++) {
          let s = Math.max(-1, Math.min(1, buf[i]));
          dv.setInt16(i * 2, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
        }

        const ambient = ambientToggle.checked && asrModeSel.value === 'server';

        if (ambient) {
          if (rms > this.vadThreshold) {
            this.lastVoiceMs = now;
            if (!this.sessionActive) {
              this.startSession('ambient').catch(err => appendMeta('ASR start failed: ' + err));
            }
          }

          if (this.sessionActive && this.wsCanSend && this.ws && this.ws.readyState === 1) {
            if (this.ws.bufferedAmount < 2_000_000) this.ws.send(ab);
          } else {
            // keep a short pre-roll so we don't clip the start
            this.preRoll.push(ab);
            if (this.preRoll.length > this.preRollMax) this.preRoll.shift();
          }

          if (this.sessionActive && this.lastVoiceMs && (now - this.lastVoiceMs) > this.silenceMs) {
            this.stopSession();
          }
        } else {
          // push-to-talk mode: send only while sessionActive
          if (this.sessionActive && this.wsCanSend && this.ws && this.ws.readyState === 1) {
            if (this.ws.bufferedAmount < 2_000_000) this.ws.send(ab);
          } else {
            this.preRoll.push(ab);
            if (this.preRoll.length > this.preRollMax) this.preRoll.shift();
          }
        }
      };

      this.captureActive = true;
      appendMeta('capture started' + (deviceId ? (' (mic: ' + deviceId.slice(0,8) + '…)') : ''));
    },

    stopCapture() {
      try { if (this.processor) this.processor.disconnect(); } catch(e) {}
      try { if (this.source) this.source.disconnect(); } catch(e) {}
      try { if (this.gain) this.gain.disconnect(); } catch(e) {}
      try { if (this.audioCtx) this.audioCtx.close(); } catch(e) {}
      try {
        if (this.stream) this.stream.getTracks().forEach(t => t.stop());
      } catch(e) {}
      this.audioCtx = null;
      this.processor = null;
      this.source = null;
      this.stream = null;
      this.gain = null;
      this.captureActive = false;
      this.preRoll = [];
    },

    _wsUrl() {
      const proto = (location.protocol === 'https:') ? 'wss' : 'ws';
      return proto + '://' + location.host + '/ws/asr';
    },

    async startSession(reason) {
      if (this.sessionActive) return;

      await this.startCapture();

      setAsrStatus('connecting…');
      setPartial('');

      const ws = new WebSocket(this._wsUrl());
      ws.binaryType = 'arraybuffer';
      this.ws = ws;
      this.sessionActive = true;
      this.wsCanSend = false;

      ws.onmessage = (evt) => {
        let msg = null;
        try { msg = JSON.parse(evt.data); } catch(e) { return; }
        if (msg.type === 'asr_ready') {
          setAsrStatus('listening (server)');
        } else if (msg.type === 'partial') {
          setPartial(msg.text || '');
        } else if (msg.type === 'final_chunk') {
          // optional debug
        } else if (msg.type === 'final') {
          setPartial('');
          if (msg.text) appendMsg('user', msg.text);
          setAsrStatus('processing…');
        } else if (msg.type === 'agent_reply') {
          const data = (msg.payload || {});
          if (data.error) appendMeta('agent error: ' + data.error);
          if (data.reply_text) appendMsg('agent', data.reply_text);
          if (data.actions && data.actions.length) appendMeta('actions: ' + JSON.stringify(data.actions));
          if (data.audio) playAgentAudio(data.audio);
          // Update speaker status from response
          if (data.speaker_info || data.speaker_name || data.voice_id) {
            updateSpeakerStatus({
              speaker_name: data.speaker_name || data.speaker_info?.speaker_name,
              voice_id: data.voice_id || data.speaker_info?.voice_id,
              is_new_speaker: data.is_new_voice || data.speaker_info?.is_new_speaker
            });
          }
          // Update tool status from response
          if (data.tool_info || data.tool_calls) {
            updateToolStatus({
              iterations: data.tool_info?.iterations || 1,
              tool_calls: data.tool_calls || data.tool_info?.tool_calls || []
            });
          }
        } else if (msg.type === 'error') {
          appendMeta('ASR error: ' + (msg.error || 'unknown'));
        }
      };

      ws.onclose = () => {
        this.ws = null;
        this.wsCanSend = false;
        this.sessionActive = false;
        setAsrStatus('idle');
        // If we're not in ambient mode, release the mic after each utterance.
        const ambient = ambientToggle.checked && asrModeSel.value === 'server';
        if (!ambient) {
          this.stopCapture();
        }
      };

      // Wait for connection open
      await new Promise((resolve, reject) => {
        ws.onopen = () => resolve();
        ws.onerror = (e) => reject(e);
      });

      const persona = (document.getElementById('persona_input').value || '').trim();
      const speakerName = (document.getElementById('speaker_name_input').value || '').trim();

      // Use actual session from state, not hardcoded value
      const sessionId = '{{ state.selected_session or "" }}' || 'session-' + Date.now();
      ws.send(JSON.stringify({
        type: 'start',
        language_code: (languageSel.value || 'en-US'),
        sample_rate_hz: 16000,
        session_id: sessionId,
        voice_id: selectedMicDeviceId || null,
        speaker_name: speakerName || null,
        personality_prompt: persona || null,
        reason: reason || ''
      }));

      // send pre-roll first
      this.wsCanSend = true;
      for (const chunk of this.preRoll) {
        if (ws.readyState === 1) ws.send(chunk);
      }
      this.preRoll = [];
      setAsrStatus('listening (server)');
    },

    stopSession() {
      if (!this.sessionActive || !this.ws) return;
      this.wsCanSend = false;
      try { this.ws.send(JSON.stringify({ type: 'stop' })); } catch(e) {}
      setAsrStatus('finalizing…');
    }
  };

  // --- Browser ASR fallback (Web Speech API) ---
  let recognition = null;
  let recognizing = false;
  if ('webkitSpeechRecognition' in window) {
    recognition = new webkitSpeechRecognition();
    recognition.continuous = false;
    recognition.interimResults = false;
    recognition.lang = 'en-US';

    recognition.onresult = function(event) {
      if (event.results && event.results.length > 0) {
        const transcript = event.results[0][0].transcript;
        appendMsg('user', transcript);
        recognizing = false;
        try { recognition.stop(); } catch(e) {}
        setAsrStatus('idle');
        sendToAgent(transcript);
      }
    };

    recognition.onerror = function(event) {
      setAsrStatus('error: ' + event.error);
      recognizing = false;
    };

    recognition.onend = function() {
      recognizing = false;
      setAsrStatus('idle');
      if (ambientToggle.checked && asrModeSel.value === 'browser') {
        try { recognition.start(); recognizing = true; setAsrStatus('ambient listening…'); } catch(e) {}
      }
    };
  }

  async function startPtt() {
    if (asrModeSel.value === 'server') {
      serverAsr.startSession('ptt').catch(e => appendMeta('ASR start failed: ' + e));
      return;
    }
    if (!recognition) {
      alert('Web Speech API not supported. Use Server (AWS Transcribe) mode.');
      return;
    }
    recognition.lang = languageSel.value || 'en-US';
    try { recognition.start(); recognizing = true; setAsrStatus('listening (browser)…'); } catch(e) {}
  }

  function stopPtt() {
    if (asrModeSel.value === 'server') {
      serverAsr.stopSession();
      return;
    }
    if (recognition && recognizing) {
      try { recognition.stop(); } catch(e) {}
      recognizing = false;
      setAsrStatus('idle');
    }
  }

  async function loadDebugTools() {
    if (!debugToolsContainer) return;
    try {
      const resp = await fetch('/api/debug/tools');
      const data = await resp.json();
      renderDebugTools(data.tools || []);
      (data.logs || []).forEach((l) => appendDebugLog(l));
    } catch (e) {
      appendDebugLog('Failed to load debug tools: ' + e);
    }
  }

  function renderDebugTools(tools) {
    debugToolsContainer.innerHTML = '';
    tools.forEach((tool) => {
      const wrapper = document.createElement('div');
      wrapper.className = 'debug-tool';

      const title = document.createElement('div');
      title.className = 'debug-tool-title';
      title.textContent = tool.label || tool.id;
      wrapper.appendChild(title);

      if (tool.description) {
        const desc = document.createElement('div');
        desc.className = 'meta';
        desc.textContent = tool.description;
        wrapper.appendChild(desc);
      }

      let inputEl = null;
      if (tool.options && tool.options.length) {
        inputEl = document.createElement('select');
        inputEl.style.marginTop = '6px';
        inputEl.style.marginRight = '6px';
        const placeholder = document.createElement('option');
        placeholder.value = '';
        placeholder.textContent = tool.param_label || 'Select option';
        inputEl.appendChild(placeholder);
        tool.options.forEach((opt) => {
          const optEl = document.createElement('option');
          optEl.value = opt;
          optEl.textContent = opt;
          inputEl.appendChild(optEl);
        });
        const preferred = tool.selected_stack || tool.default_param;
        if (preferred) inputEl.value = preferred;
        wrapper.appendChild(inputEl);
      } else if (tool.param_label) {
        inputEl = document.createElement('input');
        inputEl.type = 'text';
        inputEl.placeholder = tool.param_label;
        if (tool.default_param) inputEl.value = tool.default_param;
        inputEl.style.marginTop = '6px';
        inputEl.style.marginRight = '6px';
        wrapper.appendChild(inputEl);
      }

      const runBtn = document.createElement('button');
      runBtn.textContent = 'Run';
      runBtn.onclick = () => {
        const payload = inputEl ? { [tool.param_key || 'input']: (inputEl.value || tool.default_param || '') } : {};
        runDebugTool(tool.id, payload);
      };
      wrapper.appendChild(runBtn);

      debugToolsContainer.appendChild(wrapper);
    });
  }

  async function runDebugTool(toolId, params) {
    setDebugOutput('Running ' + toolId + '...');
    try {
      const resp = await fetch('/api/debug/run_tool', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ tool: toolId, params: params || {} })
      });
      const data = await resp.json();
      const prefix = data.ok ? '[ok]' : '[error]';
      setDebugOutput(prefix + '\n' + (data.output || ''));
      if (data.logs) {
        (data.logs || []).forEach((l) => appendDebugLog(l));
      }
    } catch (e) {
      setDebugOutput('Failed to run tool: ' + e);
    }
  }

  async function refreshVerboseLogs() {
    if (!verboseEnabled || !debugLogBox) return;
    try {
      const resp = await fetch('/api/debug/logs');
      const data = await resp.json();
      debugLogBox.innerHTML = '';
      (data.lines || []).forEach((l) => appendDebugLog(l));
    } catch (e) {
      // best-effort only
    }
  }

  // PTT button: hold to talk
  pttBtn.addEventListener('mousedown', startPtt);
  pttBtn.addEventListener('touchstart', (e) => { e.preventDefault(); startPtt(); }, {passive:false});
  window.addEventListener('mouseup', stopPtt);
  window.addEventListener('touchend', stopPtt);

  // Ambient toggle behavior
  ambientToggle.addEventListener('change', () => {
    const on = ambientToggle.checked;
    if (asrModeSel.value === 'server') {
      if (on) {
        serverAsr.startCapture().then(() => setAsrStatus('ambient armed')).catch(e => appendMeta('capture failed: ' + e));
      } else {
        serverAsr.stopSession();
        serverAsr.stopCapture();
        setAsrStatus('idle');
      }
    } else {
      if (on && recognition) {
        try { recognition.lang = languageSel.value || 'en-US'; recognition.start(); recognizing = true; setAsrStatus('ambient listening…'); } catch(e) {}
      }
    }
  });

  // ASR mode change: stop current sessions.
  asrModeSel.addEventListener('change', () => {
    setPartial('');
    stopPtt();
    serverAsr.stopSession();
    serverAsr.stopCapture();
    setAsrStatus('idle');
  });

  // Initialize device lists.
  (async () => {
    try {
      await refreshDevices();
    } catch (e) {
      appendMeta('device enumeration blocked (click “Enable audio”): ' + e);
    }
    try {
      await loadDebugTools();
      await refreshVerboseLogs();
      if (verboseEnabled) {
        setInterval(refreshVerboseLogs, 10000);
      }
    } catch (e) {
      appendDebugLog('debug init failed: ' + e);
    }
  })();
</script>
</body>
</html>
